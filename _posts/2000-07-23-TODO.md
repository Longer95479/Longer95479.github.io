- [ ] 特征提取
    - [ ] 数据关联
    - [ ] 数据结构 frame::_features and frame::_track_id
    - [ ] 流程
[ ] 运动估计
  [] 数据结构
  [] 流程
[] 后端优化 
  [] 数据结构

---

- [x] 数据集读取
  - [x] json
  - [x] csv (包含 mag 数据)

- [x] 可视化：
  - [x] 把地图显示在 rviz 上，方便调试
    - [x] 尺度上的变换
    - [x] 左上角为 (0, 0), x 向右为正，y 向下为正，x 指向北
    - [x] 定义地图系（NED，相对于 rviz 的世界系）
    - [x] 解决读取不到 .dae 文件的 bug：打开rviz的终端找不到 slampose包
    - [x] mesh 不显示：尺度变换错误，尺度太小导致看不见
    - [x] 确认 marker 的固联坐标系：见 手写笔记

- [x] 确定状态量、 观测量、因子（约束）：
  - [x] 状态
    - [x] geo_T_slamp
  - [x] 观测量 与 因子
    - [x] Local Factor(VIO) 
    - [x] GPS Factor 
    - [x] Magnetmeter Factor

- [x] 确定数据结构
  - [x] 阅读 test_PGO
  - [x] 安装源码版 pycolmap

- [x] 初始化：
  - [x] NED 坐标系下轨迹各帧初始值 = SE(3) * slam_pose
  - [x] 先将 localkit 的经纬度变换到 地理系 
  - [x] 确定平移部分：x、y 从 slampose 和 localkit 最近邻点对来获取，然后取个平均
  - [x] 确定旋转部分：yaw从磁力计获取、或者从已有轨迹和地图对齐考虑


- [x] 约束与优化：
  - [x] Local Factor(VIO): slampose 帧间位姿
  - [x] wifi/GPS Factor: localkit 找时间上最近邻的帧施加约束
  - [x] manhattan yaw
    - [x] 施加 yaw offset
    - [x] 读取 mgw 数据
    - [x] 预处理 mgw 数据
    - [x] 构建约束，和 location 一起
  - [ ] Magnetmeter Factor: 磁力计施加的 yaw 约束
  - [ ] huber 鲁棒核函数

- [x] 数据输出
  - [x] 结果转换为 rpy
  - [x] 结果打包到 list
  - [x] 按指定格式，写到指定位置下的 csv
  - [x] 0-6 数据集rosbag 图片 265 张，但 slampose 有 267 个，转成 rosbag 有点问题

- [ ] 高频传播：
  - [ ] imu propagate

一些初步结论：
- mgw 姿态比 slampose 的姿态好，因此输出只输出 mgw 的角度
- mgw 姿态 和 slampse 的平移初始值共同构成 AbsPose 先验，这个先验的方差如果设置小，也就ishi比重大一些后，会导致整体的轨迹尺度发散，这就导致 mgw 的权重无法太大，因此变成了辅助定位

第一帧使用 mag_in_imu 计算的 T 有误，甚至会影响到尺度
- 0
       mgw      slampose
  - 0: back	b
  - 1: forward	b
  - 2: b        b
  - 3: f        b
  - 4: b	b
  - 5: f	b
  - 6: b	b
  - 7: b	b
  - 8: f	b

旋转错误
- 0-4 
- 0-8
- 1-0
- 1-1	

---

pytorch 与其他框架训练的网络如何交互：onnx 开放神经网络交换

分为用于实验的即时模式，和用于高性能执行的图形模式


反向模式自动微分，Chainer
- 写一个子程序计算函数值 f(x)
- 


[A simple explanation of reverse-mode automatic differentiation](https://justindomke.wordpress.com/2009/03/24/a-simple-explanation-of-reverse-mode-automatic-differentiation/)

backpropagation algorithm:
- 本质上是链式法则

```
n = 4, N = 7

1    2    3    4
 5(1,2)  6(1, 3, 4)
      7(5, 6)

x_i <- f_i(X_{/pi(i)})
i = n + 1, ... , N


dxN/dxN <- 1
dxN/dxi <- \sum_{k: i = /pi(k)} dxN/dxk * dfk/dxi
i = N-1, N-2, ... , 1


```

```
  graph (1)

1  x1   1
   | \ /
   v  v
2  x2 x3
    \ /
     v
3    x4

x1.need_grad()
1. x2 <- f2(x1) = x1
2. x3 <- f3(x1, 1) = x1 - 1
3. x4 <- f4(x2, x3) = x2 * x3

dx4/dx4 = 1
3. dx4/dx3 = dx4/dx4 * df4/dx3 = x2
2. dx4/dx2 = dx4/dx4 * df4/dx2 = x3
1. dx4/dx1 = dx4/dx2 * df2/dx1 + dx4/dx3 * df3/dx1
           = x3 * 1 + x2 * 1
           = x1 - 1 + x1
           = 2x1 - 1

  graph (2)

1  x1
   | \
   |  v
2  |  x2
   | /
   v
3  x3

x1.need_grad()
1. x2 <- f2(x1) = x1 - 1
2. x3 <- f3(x1, x2) = x1 * x2

dx3/dx3 = 1
2. dx3/dx2 = dx3/dx3 * df3/dx2 = x1
1. dx3/dx1 = dx3/dx3 * df3/dx1 + dx3/dx2 * df2/dx1
           = x2 + x1 * 1
           = x1 - 1 + x1
           = 2x1 - 1

```

graph


The biggest difference is that autodiff can differentiate algorithms, not just expressions


---

2024-04-20

PyTorch is a Python-based scientific computing package serving two broad purposes:

A replacement for NumPy to use the power of GPUs and other accelerators.

An automatic differentiation library that is useful to implement neural networks.


---


[Pi0](https://www.bilibili.com/video/BV1mERzYvE4j/?spm_id_from=333.1007.tianma.2-2-5.click&vd_source=e371652571b1539bbd501fb7adb6cfc4)


1. 社区更好地掌握了创建可迁移通用模型的方法，使得微调或零样本迁移到其他机器人上成为可能
2. 视觉语言模型，让机器人能够理解环境中的语义
3. 强化学习领域的进步，使系统的健壮性、可靠性、性能得到突破


---

[](https://www.bilibili.com/video/BV1qqUaYmENu/?spm_id_from=333.788.recommend_more_video.-1&vd_source=e371652571b1539bbd501fb7adb6cfc4)

LLM：文字 -> 文字
VLM：图片+文字 -> 文字
VLA：图片+文字+Robot Action Data -> Robot Action Data

通用模型比专用系统表现更好
纳入异质数据源显著提升了繁华能力


训练基础模型的流程：
- 预训练：爬虫、筛选巨大的预训练数据集 -> 设计网络架构（一般是 Transformer）-> 设计训练目标
- 



---

C 语言模板库得到的启示：

如何在 C 语言中构建 类 呢
- 使用结构体 struct
  - property：需要初始化的成员变量
  - value：用于缓存
  - 函数指针

使用的步骤：
 - 核心思路是三步走：
    - 成员变量（普通变量+函数指针）初始化（赋初值）
    - 通过函数指针调用算法初始化函数
    - 再通过函数指针调用逻辑执行函数

 - C++ 有构造函数，而在 C 里，则需要单独写一个 全局函数，用于将 函数指针 绑定（被赋值）到某个具体的函数实现上


---

- [ ] 把 DD 相关的写完，总结好

- [ ] vins 初始化流程
  - [x] c0bk 意味着是以 c0 为参考，因此尺度 s 不确定

- [ ] 理解 plnet 的 pipline 以及 数据结构
  - [ ] pipline、基本公式（如果有的话）
  - [ ] 如何在代码上把 onnx 转成 engine
  - [ ] 数据结构

- [ ] 自己实现一个智能指针

- [ ] 初学 diffusion 原理
- [ ] 初学 Transformer 原理
- [ ] 初学 RL 原理

- [ ] 复习 Pytorch
- [ ] PCL 库学习


---

依赖：
- NvOnnxParser.h
- 3rdparty/tensorrtbuffer/include/buffers.h
- Eigen/core
- opencv.hpp


resize 图片相关:
- input_width, input_height


---

keynote: The Real Problem of C++ - Klaus


c++ has a safety problem
- yes if you still have the "classic C++" midset

always choose perfomence, cuz:
- YES: safe over fast
- NO: fast over safe

topic:
- Bound Safety
- Type Safety
- Initialization Safety
- Lifetime Safety
- Undefined Behavior
 
1. Bound Safety	

The first part about ranges and not using loops, that's mainly about using a declarative style - so that your code says what it does, but not how it does that, and every common part of the logic (like take) is a separate library function (tested billions times unlike the for loop you make instead). 



- the "Ranges" style.
```
std::ranges::sort()
```

和 `std::sort` 有什么区别?

- **No Raw Loops**

代码示例见视频


2. undedined Behavior

- using `constexpr`
`-std=c++20` 才好用，否则无法在 constexpr 的函数内创建 vector 等数据结构

- complier explorer 是个好工具

- 函数只能全特化，不能偏特化（全特化意味着template<>，也就是括号里得为空，然后在函数名后3所有具体的类型名）


---

`explicit` 关键字用于一个参数的函数，一般用于 构造函数，禁止隐式转换的发生


boost::bind 可以在运行时动态创建 可调用对象

如果函数不在类内，则 
```
int add(int a, int b) { return a + b; }
auto add2 = boost::bind(add, 2, _1);
add2(3); // 5
```
否则：
```
one_class(){
  ...
  _one_thread = std::thread(std::bind(&one_class::method, this));
  ...
}
```

---

RAII(Resource Acquisition Is Initialization):
资源获取即初始化。利用存储在栈的对象，来管理资源

1. 设计一个类封装资源
2. 在构造函数中初始化资源
3. 在析构函数中销毁资源
4. 使用时声明一个该类的对象

[c++经验之谈一：RAII原理介绍](https://zhuanlan.zhihu.com/p/34660259)
---

一个 procedure A 调用另一个 procedure B 时，计算机需要干的事情：

1. 转移控制
2. 转移数据
3. 分配和释放内存


```c
int fact(int n)
{
  int result;
  if (n <= 1)
    result = 1;
  else
    result = n * fact(n-1);
  return result;
}
```


main() -> fact(n) -> fact(n-1) 即将-> fact(n-2)
的 call stack: 

```
      (stack top)
  +-----------------+ <-- stack pointer (SP)
  |      n - 2      | \  
  +-----------------+  | 
  |      result     |   > frame for fact(n-1)
  +-----------------+  | 
  |  saved register | /  
  +-----------------+
  |  return address | \  
  +-----------------+  |  
  |      n - 1      |  | 
  +-----------------+   > frame for fact(n)
  |      result     |  | 
  +-----------------+  |
  | saved registers | /
  +-----------------+
  |  return address | \  
  +-----------------+  | 
  |        n        |   > frame for main()
  +-----------------+  | 
  |       ...       | /  
  +-----------------+
    (stack "bottom")
```
---


# 设计模式

[工厂模式比较](https://refactoringguru.cn/design-patterns/factory-comparison)

- 构建方法：返回一个对象的函数或方法
```c++
class number {
  number(v): value(v) {}
  unique_ptr<widget> nextFactory() {
    return make_unique<number>(value + 1);
  }
private:
  int value;
}
```

- 简单工厂模式

简单工厂通常没有子类。 但当从一个简单工厂中抽取出子类后， 它看上去就会更像经典的工厂方法模式了。

```c++
class Button {/* ... */}; 
class WinButton: Botton {/* ... */};
class MacButton: Botton {/* ... */};

class ButtonFactory {
  unique_ptr<Button> create(string type) {
    switch (type) {
      case "Mac": return make_unique<MacButton>
      case "Win": return make_unique<WinButton>
      default: cout << "Wrong type." << endl; return nullptr;
    }
  }
}
```


- 工厂方法模式
```c++
class Button {/* ... */}; 
class WinButton: Botton {/* ... */};
class MacButton: Botton {/* ... */};

class ButtonFactory {
  vitual unique_ptr<Botton> createButton()=0;
}

class MacButtonFactory: ButtonFactory{
  unique_ptr<Botton> createButton() {
    return make_unique<MacButton>();
  }
}

class WinButtonFactory: ButtonFactory{
  unique_ptr<Botton> createButton() {
    return make_unique<WinButton>();
  }
}
```


- 抽象工厂

抽象工厂 是一种创建型设计模式， 它能创建一系列相关或相互依赖的对象， 而无需指定其具体类。

什么是 “系列对象”？ 例如有这样一组的对象：运输工具+ 引擎+ 控制器 。 它可能会有几个变体：

1. 汽车+ 内燃机+ 方向盘
2. 飞机+ 喷气式发动机+ 操纵杆

如果你的程序中并不涉及产品系列的话， 那就不需要抽象工厂。

再次重申， 许多人分不清抽象工厂模式和声明为 abstract的简单工厂。 不要犯这个错误！

example:

产品结构：

```
class Button; // Abstract Class

class MacButton: public Button {};

class WinButton: public Button {};

class Border; // Abstract Class

class MacBorder: public Border {};

class WinBorder: public Border {};
```

对应的工厂：

```
class AbstractFactory {
public:
    virtual Button* CreateButton() =0;
    virtual Border* CreateBorder() =0;
};

class MacFactory: public AbstractFactory {
public:
    MacButton* CreateButton() { return new MacButton; }
    MacBorder* CreateBorder() { return new MacBorder; }
};

class WinFactory: public AbstractFactory {
public:
    WinButton* CreateButton() { return new WinButton; }
    WinBorder* CreateBorder() { return new WinBorder; }
};
```
那么客户可以根据需要选择 Mac 风格或者 Win 风格来创建 Button 或 Border:

```
AbstractFactory* fac;
switch (style) {
case MAC:
    fac = new MacFactory;
    break;
case WIN:
    fac = new WinFactory;
    break;
}
Button* button = fac->CreateButton();
Border* border = fac->CreateBorder();
```

---


## lambda

```
 1
 ^
/ \
[=] () mutable throw() -> int
{
  int n = x + y;

  x = y;
  y = n;

  return n;
}
```


---

- [x] “发明内容“后半部分：增加三步骤的图；文字部分
- [x] ”具体实施方式二：边界跟踪算法“ 修改公式，以及配图
- [x] 权利要求书对应的公式
- [x] 更新表 1
- [ ] 解决 visio 图模糊


---


禾多科技

1. 为什么一般滤波比优化速度更快

可以从 优化变量个数 和 优化迭代次数 两方面对比。

优化个数：滤波只考虑当前状态和下一状态，窗口2；优化则有更多的变量参与，窗口较大

迭代次数：卡尔曼滤波只线性化一次（预测和更新算一次），而优化有多次线性化

额外思考：
```
微分方程 -> 离散递推 -> 即两个状态间的约束（优化/因子图角度）
               |
               v
            预测（滤波角度）
```


2. 旋转矩阵的一些特性，维度，列向量模长，含义等

特性：R^TR = I，det(R) > 0
维度：9 个参数，3 个自由度
列向量模长：1
含义：如果 R 能够把一个向量的坐标，从 B 坐标系 变换到 A 坐标系，那么 R 的三个列向量是 B 坐标系三个轴在 A 坐标系下的坐标/表达。


3. 粒子滤波，ICP，NDT，GICP 的区别，重定位问题怎么做的？

- [ ] 粒子滤波：非参数化的蒙特卡洛方法

- [ ] ICP

- [ ] NDT

- [ ] GICP 

- [ ] 重定位问题怎么做的：看一下 airslam 的重定位方案

4. 高斯牛顿在什么时候失效

- 初始值不准确 + 目标函数非凸
- 可能被鞍点吸引

f(x) = r^T(x) r(x)

- 牛顿法：相当于把目标函数 f(x) = f(x0) + \Nabla f^T(x0)(x-x0) + H 二阶展开，然后利用 梯度为0 去求解
- 高斯牛顿：不直接求解海塞矩阵，而是进行近似


5. 地面点分割的方法

- [基于几何特征的地面点云分割](https://zhuanlan.zhihu.com/p/34815976)

- 水平面校准

- 基于栅格：1）生成栅格；2）计算栅格内高度差；3）给栅格分类
- 基于法向量
- 基于绝对高度

6. 预积分 bias 的处理

先梳理一下预积分的思路

1. 状态的微分方程组 -> 积分形式
2. 假设 a 和 w 短时间恒定，简化积分形式
3. 代入 a 和 w 的测量模型，假设短时间 R 没变，得到 递推式
4. 将递推写成求和形式，把 pvR 移到同一边，得到 最初始预积分公式
5. 将 \delta pvR 变换到 第 i 帧下（我们称相邻两帧为第 i，j 帧），从而将测量侧的 Rwk 变成 Rik，但此时测量侧还有状态量 vik
6. p 等式左右减去 vii，再根据 v 的 预积分测量部分形式，减去 g


```
原始预测约束（原始测量 ，状态）= 0
               | 
     ----------- f
     |
     v 
预积分测量 = 预积分预测模型（状态）
```

用 f(b) 表示预积分原始测量到预积分测量的映射，当 b 在迭代过程中变化较大时，就该更新 f(b) <- f(b) + J^f_b \delta b


